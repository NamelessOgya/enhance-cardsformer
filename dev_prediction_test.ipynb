{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91ae877d-a4ad-4238-94fa-5157d41b18a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/s2430014/research/enhance-cardsformer-dev/Cardsformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd Cardsformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b35c37f-8c69-4153-854c-47256a075fb8",
   "metadata": {},
   "source": [
    "# prediction modelの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4871d67-433b-4e31-9e42-b10941ec2b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coreclr\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 環境変数を設定\n",
    "os.environ[\"PYTHONNET_RUNTIME\"] = \"coreclr\"\n",
    "\n",
    "# 設定した環境変数を取得\n",
    "print(os.environ[\"PYTHONNET_RUNTIME\"])\n",
    "\n",
    "from typing import OrderedDict\n",
    "from Env.Hearthstone import Hearthstone\n",
    "from Env.EnvWrapper import Environment\n",
    "from Model.PredictionModel import PredictionModel\n",
    "from Model.ModelWrapper import Model as PolicyModel\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "from Algo.encoder import Encoder\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ac780f5-1ff3-4d40-afdc-ee09b82dfaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b266cd3-c27c-4f24-a516-3058bafe2abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c80acae-b0df-40cc-a2a1-c443c1de97ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/s2430014/research/enhance-cardsformer-dev/Cardsformer\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "334a9d23-2a7f-4a1d-bb37-f76a2eac5158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "\n",
    "class PredictionDataset(Dataset):\n",
    "\n",
    "    def __init__(self, id_list, test=False, data_name='./off_line_data'):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.data = {\n",
    "            'hand_card_names': [],\n",
    "            'minion_names': [],\n",
    "            'weapon_names': [],\n",
    "            'hand_card_scalar': [],\n",
    "            'minion_scalar': [],\n",
    "            'hero_scalar': [],\n",
    "            'next_state_minion_scalar': [],\n",
    "            'next_state_hero_scalar': [],\n",
    "\n",
    "        }\n",
    "        for id in id_list:\n",
    "            print(f\"=== load prediction dataset id={id}, dataname={data_name} ===\")\n",
    "            if test:\n",
    "                data_path = './test_data' + str(id) + '.npy'\n",
    "            else:\n",
    "                data_path = data_name + str(id) + '.npy'\n",
    "            cur_data = np.load(data_path, allow_pickle=True).item()\n",
    "            for key in cur_data:\n",
    "                if key == 'secret_names':\n",
    "                    continue\n",
    "                self.data[key] += cur_data[key]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['hand_card_names'])\n",
    "\n",
    "    def __getitem__(self, index, id=False):\n",
    "        return self.data['hand_card_names'][index], self.data['minion_names'][index], self.data['weapon_names'][index], self.data['hand_card_scalar'][index], self.data['minion_scalar'][index], self.data['hero_scalar'][index], self.data['next_state_minion_scalar'][index], self.data['next_state_hero_scalar'][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c28a7195-5456-41ef-917a-170e3f6461af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for PredictionModel:\n\tsize mismatch for hand_card_feat_embed.weight: copying a param with shape torch.Size([63, 23]) from checkpoint, the shape in current model is torch.Size([63, 24]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     name \u001b[38;5;241m=\u001b[39m k[\u001b[38;5;241m7\u001b[39m:]\n\u001b[1;32m      9\u001b[0m     new_state_dict[name] \u001b[38;5;241m=\u001b[39m v\n\u001b[0;32m---> 11\u001b[0m \u001b[43mprediction_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_state_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m prediction_model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m prediction_model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for PredictionModel:\n\tsize mismatch for hand_card_feat_embed.weight: copying a param with shape torch.Size([63, 23]) from checkpoint, the shape in current model is torch.Size([63, 24])."
     ]
    }
   ],
   "source": [
    "prediction_model = PredictionModel(is_train=True)\n",
    "    # prediction\n",
    "checkpoint_states = torch.load(\"./trained_models/prediction_model4715.tar\", map_location=\"cpu\")['model_state_dict']\n",
    "\n",
    " # unwrap the prediction model\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in checkpoint_states.items():\n",
    "    name = k[7:]\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "prediction_model.load_state_dict(new_state_dict)\n",
    "prediction_model.to(\"cpu\")\n",
    "prediction_model.eval()\n",
    "device = \"cpu\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "auto_model = AutoModel.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "encoder = Encoder(model=auto_model, tokenizer=tokenizer)\n",
    "encoder.to(device)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f5544b-4171-4f52-abc2-4cfd17252d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== load prediction dataset id=8, dataname=./off_line_data ===\n"
     ]
    }
   ],
   "source": [
    "# data = PredictionDataset([0], data_name=\"off_line_data_vs_ai\")\n",
    "data = PredictionDataset([8])\n",
    "data_l = DataLoader(data, batch_size=100, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4450cc61-21f1-4f4d-8e5b-166999bd7e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "for n, batch in enumerate(data_l):\n",
    "    if n % 100 == 0:\n",
    "        print(f\"batch {n} processed\")\n",
    "    \n",
    "    for i in range(8):\n",
    "        batch[i] = batch[i].float().to(device)\n",
    "    x = [batch[i] for i in range(6)] #これはなに\n",
    "    y = [batch[6], batch[7]] #これはなに\n",
    "    with torch.no_grad():\n",
    "        pred = prediction_model(x)\n",
    "\n",
    "    loss1 = loss_fn(y[0], pred[0])\n",
    "    loss2 = loss_fn(y[1], pred[1])\n",
    "    loss = loss1 + loss2\n",
    "    \n",
    "    losses.append(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e2f3c-1415-4a04-a305-5180b2584b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(losses) / len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdbc987-b59b-4607-abbe-ff9481c42153",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = PredictionDataset([0], data_name=\"off_line_data_vs_ai\")\n",
    "data_l = DataLoader(data, batch_size=100, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1ef58a-0f2e-4531-9d69-3539a48608d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "print(f\"data length is {len(data_l)}\")\n",
    "\n",
    "for n, batch in enumerate(data_l):\n",
    "    if n % 100 == 0:\n",
    "        print(f\"batch {n} processed\")\n",
    "    \n",
    "    for i in range(8):\n",
    "        batch[i] = batch[i].float().to(device)\n",
    "    x = [batch[i] for i in range(6)] #これはなに\n",
    "    y = [batch[6], batch[7]] #これはなに\n",
    "    with torch.no_grad():\n",
    "        pred = prediction_model(x)\n",
    "\n",
    "    loss1 = loss_fn(y[0], pred[0])\n",
    "    loss2 = loss_fn(y[1], pred[1])\n",
    "    loss = loss1 + loss2\n",
    "    \n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4f5605-e04e-4d7b-b947-93af1ae801d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(losses) / len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8096638b-0b30-4285-bdc2-150f2a340093",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
